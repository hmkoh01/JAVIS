#!/usr/bin/env python3
import os
import sys
from pathlib import Path

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬(backend)ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
backend_dir = Path(__file__).parent.parent.absolute()
if str(backend_dir) not in sys.path:
    sys.path.insert(0, str(backend_dir))

import time
import json
import sqlite3
import psutil
import platform
import threading
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
import asyncio
import plistlib
import aiofiles
try:
    import winreg  # Windows only
except ImportError:
    winreg = None  # macOS/Linuxì—ì„œëŠ” Noneìœ¼ë¡œ ì„¤ì •
import subprocess
import numpy as np
import hashlib
try:
    from PIL import ImageGrab  # Windows/macOS with PIL support
except ImportError:
    ImageGrab = None  # Fallback for systems without PIL ImageGrab support

from config.settings import settings

# RAG ì‹œìŠ¤í…œ ì—°ë™ì„ ìœ„í•œ import
from .repository import Repository
from .sqlite_meta import SQLiteMeta
from agents.chatbot_agent.rag.models.colqwen2_embedder import ColQwen2Embedder   

class FileCollector:
    """ì‚¬ìš©ì ë“œë¼ì´ë¸Œì˜ íŒŒì¼ë“¤ì„ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, user_id: int):
        self.user_id = user_id
        self.sqlite_meta = SQLiteMeta()
        
        # ìˆ˜ì§‘í•  íŒŒì¼ í™•ì¥ì ëª©ë¡ (í—ˆìš© ë¦¬ìŠ¤íŠ¸)
        self.supported_extensions = {
            'document': ['.txt', '.doc', '.docx', '.pdf', '.hwp', '.md'],
            'spreadsheet': ['.xls', '.xlsx', '.csv', '.ods'],
            'presentation': ['.ppt', '.pptx', '.odp'],
            'code': ['.py', '.js', '.html', '.css', '.java', '.cpp'],
        }
        
        # ğŸ’¡ í—ˆìš©í•  í™•ì¥ì ëª©ë¡ì„ í•˜ë‚˜ì˜ ì„¸íŠ¸(set)ë¡œ í†µí•© (íš¨ìœ¨ì ì¸ íƒìƒ‰ì„ ìœ„í•´)
        self.allowed_extensions = set()
        for extensions in self.supported_extensions.values():
            self.allowed_extensions.update(extensions)
            
        # íŒŒì¼ í•´ì‹œ ìºì‹œ (ì¤‘ë³µ ë°©ì§€ìš©)
        self.file_hash_cache = {}
        
    def get_file_category(self, file_path: str) -> str:
        """íŒŒì¼ í™•ì¥ìë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        ext = Path(file_path).suffix.lower()
        
        for category, extensions in self.supported_extensions.items():
            if ext in extensions:
                return category
        return 'other'
    
    def should_skip_directory(self, dir_path: str) -> bool:
        """ìˆ˜ì§‘í•˜ì§€ ì•Šì„ ë””ë ‰í† ë¦¬ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤."""
        skip_patterns = [
            'Windows', 'Program Files', 'Program Files (x86)', 
            '$Recycle.Bin', 'System Volume Information', '.git',
            'node_modules', '__pycache__', '.vscode', '.idea',
            'AppData', 'Temp', 'tmp', 'ProgramData', 'Recovery',
            'Boot', 'EFI', 'MSOCache'
        ]
        
        path_parts = Path(dir_path).parts
        return any(part in skip_patterns for part in path_parts)
    
    # âŒ ê¸°ì¡´ì˜ ë³µì¡í–ˆë˜ should_skip_file ë©”ì„œë“œëŠ” ì‚­ì œí•©ë‹ˆë‹¤.

    def calculate_file_hash(self, file_path: str) -> str:
        """íŒŒì¼ì˜ í•´ì‹œê°’ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        try:
            if os.path.getsize(file_path) > 100 * 1024 * 1024:  # 100MB
                return f"large_file_{os.path.getsize(file_path)}"
            
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                chunk = f.read(1024 * 1024) # 1MBë§Œ ì½ì–´ í•´ì‹œ ê³„ì‚°
                hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            # print(f"íŒŒì¼ í•´ì‹œ ê³„ì‚° ì˜¤ë¥˜ {file_path}: {e}") # ë¡œê·¸ ìµœì†Œí™”
            return f"error_{int(time.time())}"
    
    def is_file_duplicate(self, file_path: str, file_hash: str) -> bool:
        """íŒŒì¼ì´ ì¤‘ë³µì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            return self.sqlite_meta.is_file_hash_exists(file_hash)
        except Exception as e:
            print(f"ì¤‘ë³µ ì²´í¬ ì˜¤ë¥˜ {file_path}: {e}")
            return False
    
    def is_file_modified(self, file_path: str, last_modified: datetime) -> bool:
        """íŒŒì¼ì´ ìˆ˜ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        try:
            stored_modified = self.sqlite_meta.get_file_last_modified(file_path)
            if stored_modified is None:
                return True
            return last_modified > stored_modified
        except Exception as e:
            print(f"íŒŒì¼ ìˆ˜ì • ì²´í¬ ì˜¤ë¥˜ {file_path}: {e}")
            return True
    
    def get_c_drive_folders(self) -> List[Dict[str, Any]]:
        print("get_c_drive_folders ë©”ì„œë“œ ì‹œì‘")
        folders = []
        base_path = "C:\\Users\\choisunwoo\\Desktop"
        
        try:
            print(f"ê¸°ì¤€ ê²½ë¡œ: {base_path}")
            
            # ê¸°ì¤€ ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if not os.path.exists(base_path):
                print(f"ê¸°ì¤€ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_path}")
                return folders
            
            items = os.listdir(base_path)
            print(f"ê¸°ì¤€ ê²½ë¡œ í•­ëª© ê°œìˆ˜: {len(items)}")
            
            for item in items:
                item_path = os.path.join(base_path, item)
                print(f"í™•ì¸ ì¤‘: {item_path}")
                
                if os.path.isdir(item_path):
                    print(f"  - ë””ë ‰í† ë¦¬ì„: {item}")
                    if not self.should_skip_directory(item_path):
                        print(f"  - ìŠ¤í‚µí•˜ì§€ ì•ŠìŒ: {item}")
                        # í´ë” ì •ë³´ ìˆ˜ì§‘
                        try:
                            stat = os.stat(item_path)
                            folder_info = {
                                'name': item,
                                'path': item_path,
                                'created_date': datetime.fromtimestamp(stat.st_ctime),
                                'modified_date': datetime.fromtimestamp(stat.st_mtime),
                                'size': self._get_folder_size(item_path)
                            }
                            folders.append(folder_info)
                            print(f"  - ì¶”ê°€ë¨: {item}")
                        except (PermissionError, OSError) as e:
                            # ì ‘ê·¼ ê¶Œí•œì´ ì—†ëŠ” í´ë”ëŠ” ê±´ë„ˆë›°ê¸°
                            print(f"  - ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ: {item} - {e}")
                            continue
                    else:
                        print(f"  - ìŠ¤í‚µë¨: {item}")
                else:
                    print(f"  - íŒŒì¼ì„: {item}")
                        
        except Exception as e:
            print(f"í´ë” ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            
        # ì´ë¦„ìˆœìœ¼ë¡œ ì •ë ¬
        folders.sort(key=lambda x: x['name'].lower())
        print(f"ìµœì¢… í´ë” ê°œìˆ˜: {len(folders)}")
        return folders
    
    def _get_folder_size(self, folder_path: str) -> int:
        """í´ë”ì˜ ëŒ€ëµì ì¸ í¬ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        total_size = 0
        try:
            for dirpath, dirnames, filenames in os.walk(folder_path):
                for filename in filenames:
                    try:
                        filepath = os.path.join(dirpath, filename)
                        total_size += os.path.getsize(filepath)
                    except (OSError, FileNotFoundError):
                        continue
        except Exception:
            pass
        return total_size

    def _collect_files_from_selected_folders(self, selected_folders: List[str], incremental: bool = True, manager: Optional['DataCollectionManager'] = None) -> List[Dict[str, Any]]:
        """ì„ íƒëœ í´ë”ë“¤ì—ì„œë§Œ íŒŒì¼ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        collected_files = []
        total_folders = len(selected_folders)
        processed_folders = 0
        
        last_update_time = time.time()
        update_interval = 0.1
        
        for folder_path in selected_folders:
            if not os.path.exists(folder_path) or not os.path.isdir(folder_path):
                print(f"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
                continue
                
            try:
                if manager:
                    processed_folders += 1
                    progress = (processed_folders / total_folders) * 80.0
                    manager.progress = progress
                    manager.progress_message = f"ğŸ“ ìŠ¤ìº” ì¤‘: {folder_path}"
                
                for root, dirs, files in os.walk(folder_path):
                    # ìŠ¤í‚µí•  ë””ë ‰í† ë¦¬ í•„í„°ë§
                    dirs[:] = [d for d in dirs if not self.should_skip_directory(os.path.join(root, d))]
                    
                    for file in files:
                        if manager:
                            current_time = time.time()
                            if current_time - last_update_time > update_interval:
                                folder_scan_message = manager.progress_message.split(' | ')[0]
                                manager.progress_message = f"{folder_scan_message} | ğŸ” {file[:50]}"
                                last_update_time = current_time

                        try:
                            file_path = os.path.join(root, file)
                            
                            # í—ˆìš©ëœ í™•ì¥ìì¸ì§€ í™•ì¸
                            file_ext = Path(file_path).suffix.lower()
                            if file_ext not in self.allowed_extensions:
                                continue
                            
                            stat = os.stat(file_path)
                            modified_date = datetime.fromtimestamp(stat.st_mtime)
                            
                            if incremental and not self.is_file_modified(file_path, modified_date):
                                continue
                            
                            file_hash = self.calculate_file_hash(file_path)
                            
                            if self.is_file_duplicate(file_path, file_hash):
                                continue
                            
                            file_info = {
                                'user_id': self.user_id,
                                'file_path': file_path,
                                'file_name': file,
                                'file_size': stat.st_size,
                                'file_type': file_ext,
                                'file_category': self.get_file_category(file_path),
                                'file_hash': file_hash,
                                'created_date': datetime.fromtimestamp(stat.st_ctime),
                                'modified_date': modified_date,
                                'accessed_date': datetime.fromtimestamp(stat.st_atime),
                                'discovered_at': datetime.utcnow()
                            }
                            
                            collected_files.append(file_info)
                            
                        except (PermissionError, OSError):
                            continue
                        except Exception as e:
                            print(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ {file_path}: {e}")
                            continue
                            
            except Exception as e:
                print(f"í´ë” ìŠ¤ìº” ì˜¤ë¥˜ {folder_path}: {e}")
                continue
                
        return collected_files

    def collect_files_from_drive(self, drive_path: str = "C:\\", incremental: bool = True, manager: Optional['DataCollectionManager'] = None, selected_folders: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """ì§€ì •ëœ ë“œë¼ì´ë¸Œì—ì„œ íŒŒì¼ë“¤ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        collected_files = []
        
        # ì„ íƒëœ í´ë”ê°€ ìˆìœ¼ë©´ í•´ë‹¹ í´ë”ë“¤ë§Œ ìŠ¤ìº”
        if selected_folders:
            return self._collect_files_from_selected_folders(selected_folders, incremental, manager)
        
        # ê¸°ì¡´ ë¡œì§: ì „ì²´ ë“œë¼ì´ë¸Œ ìŠ¤ìº”
        top_level_dirs = []
        total_dirs = 1
        processed_dirs = 0
        if manager and not incremental:
            try:
                top_level_dirs = [d for d in os.listdir(drive_path) if os.path.isdir(os.path.join(drive_path, d)) and not self.should_skip_directory(d)]
                total_dirs = len(top_level_dirs)
            except Exception as e:
                print(f"ìµœìƒìœ„ ë””ë ‰í† ë¦¬ ëª©ë¡ ìƒì„± ì˜¤ë¥˜: {e}")
                top_level_dirs = []
                total_dirs = 1

        last_update_time = time.time()
        update_interval = 0.1

        try:
            for root, dirs, files in os.walk(drive_path):
                if manager and not incremental and total_dirs > 0 and top_level_dirs:
                    try:
                        current_top_dir = root.split(os.sep)[1] if len(root.split(os.sep)) > 1 else ""
                        if current_top_dir and current_top_dir in top_level_dirs:
                            current_index = top_level_dirs.index(current_top_dir)
                            if current_index >= processed_dirs:
                                processed_dirs = current_index + 1
                                progress = (processed_dirs / total_dirs) * 80.0
                                manager.progress = progress
                                manager.progress_message = f"ğŸ“ ìŠ¤ìº” ì¤‘: {os.path.join(drive_path, current_top_dir)}"
                    except Exception:
                        pass

                dirs[:] = [d for d in dirs if not self.should_skip_directory(os.path.join(root, d))]
                
                for file in files:
                    if manager:
                        current_time = time.time()
                        if current_time - last_update_time > update_interval:
                            dir_scan_message = manager.progress_message.split(' | ')[0]
                            manager.progress_message = f"{dir_scan_message} | ğŸ” {file[:50]}"
                            last_update_time = current_time

                    try:
                        file_path = os.path.join(root, file)
                        
                        # âœ… í—ˆìš©ëœ í™•ì¥ìì¸ì§€ ë¨¼ì € í™•ì¸í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½
                        file_ext = Path(file_path).suffix.lower()
                        if file_ext not in self.allowed_extensions:
                            continue
                        
                        stat = os.stat(file_path)
                        modified_date = datetime.fromtimestamp(stat.st_mtime)
                        
                        if incremental and not self.is_file_modified(file_path, modified_date):
                            continue
                        
                        file_hash = self.calculate_file_hash(file_path)
                        
                        if self.is_file_duplicate(file_path, file_hash):
                            continue
                        
                        file_info = {
                            'user_id': self.user_id,
                            'file_path': file_path,
                            'file_name': file,
                            'file_size': stat.st_size,
                            'file_type': file_ext,
                            'file_category': self.get_file_category(file_path),
                            'file_hash': file_hash,
                            'created_date': datetime.fromtimestamp(stat.st_ctime),
                            'modified_date': modified_date,
                            'accessed_date': datetime.fromtimestamp(stat.st_atime),
                            'discovered_at': datetime.utcnow()
                        }
                        
                        collected_files.append(file_info)
                        
                    except (PermissionError, OSError):
                        continue
                    except Exception as e:
                        print(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ {file_path}: {e}")
                        continue
                        
        except Exception as e:
            print(f"ë“œë¼ì´ë¸Œ ìŠ¤ìº” ì˜¤ë¥˜: {e}")
            
        return collected_files

    # ... (FileCollectorì˜ ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ì´ì „ê³¼ ë™ì¼) ...
    def save_files_to_db(self, files: List[Dict[str, Any]]) -> int:
        """ìˆ˜ì§‘ëœ íŒŒì¼ë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ë°°ì¹˜ ì €ì¥í•˜ê³  RAG ì‹œìŠ¤í…œì— ì¸ë±ì‹±í•©ë‹ˆë‹¤."""
        if not files:
            return 0
        
        saved_count = 0
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)
        repo = None
        embedder = None
        try:
            repo = Repository()
            embedder = ColQwen2Embedder()
            print("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨, SQLiteë§Œ ì €ì¥: {e}")
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
        batch_size = 50  # ë°°ì¹˜ í¬ê¸° ì„¤ì •
        text_chunks_for_embedding = []
        image_files_for_embedding = []
        file_metadata_batch = []
        
        # 1ë‹¨ê³„: SQLite ë°°ì¹˜ ì €ì¥
        print(f"ğŸ’¾ {len(files)}ê°œ íŒŒì¼ì„ SQLiteì— ë°°ì¹˜ ì €ì¥ ì¤‘...")
        try:
            # íŠ¸ëœì­ì…˜ ì‹œì‘
            self.sqlite_meta.conn.execute("BEGIN TRANSACTION")
            
            for file_info in files:
                try:
                    success = self.sqlite_meta.insert_collected_file(file_info)
                    if success:
                        saved_count += 1
                        file_metadata_batch.append(file_info)
                        
                        # RAG ì¸ë±ì‹±ìš© ë°ì´í„° ì¤€ë¹„
                        if repo and embedder:
                            file_category = file_info['file_category']
                            if file_category in ['document', 'spreadsheet', 'presentation', 'code']:
                                text_chunks_for_embedding.append(file_info)
                            elif file_category == 'image':
                                image_files_for_embedding.append(file_info)
                                
                except Exception as e:
                    print(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜ {file_info['file_path']}: {e}")
                    continue
            
            # íŠ¸ëœì­ì…˜ ì»¤ë°‹
            self.sqlite_meta.conn.commit()
            print(f"âœ… SQLite ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ íŒŒì¼")
            
        except Exception as e:
            self.sqlite_meta.conn.rollback()
            print(f"âŒ SQLite ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0
        
        # 2ë‹¨ê³„: RAG ì‹œìŠ¤í…œ ë°°ì¹˜ ì¸ë±ì‹±
        if repo and embedder and (text_chunks_for_embedding or image_files_for_embedding):
            print(f"ğŸ” RAG ì‹œìŠ¤í…œ ë°°ì¹˜ ì¸ë±ì‹± ì‹œì‘...")
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬
            if text_chunks_for_embedding:
                self._batch_index_text_files(text_chunks_for_embedding, repo, embedder, batch_size)
            
            # ì´ë¯¸ì§€ íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬
            if image_files_for_embedding:
                self._batch_index_image_files(image_files_for_embedding, repo, embedder, batch_size)
            
            print("âœ… RAG ì‹œìŠ¤í…œ ë°°ì¹˜ ì¸ë±ì‹± ì™„ë£Œ")
        
        return saved_count

    def _batch_index_text_files(self, text_files: List[Dict[str, Any]], repo: Repository, embedder: ColQwen2Embedder, batch_size: int):
        """í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ë°°ì¹˜ë¡œ ì¸ë±ì‹±"""
        try:
            all_chunks = []
            all_metas = []
            all_doc_ids = []
            
            # ëª¨ë“  í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ì²­í¬ ìˆ˜ì§‘
            for file_info in text_files:
                try:
                    file_path = file_info['file_path']
                    content = self._extract_text_content(file_path)
                    if not content:
                        continue
                    
                    chunks = self._chunk_text(content, chunk_size=1000)
                    doc_id = f"file_{hash(file_path)}"
                    
                    for i, chunk in enumerate(chunks):
                        all_chunks.append(chunk)
                        all_metas.append({
                            'page': i + 1,
                            'snippet': chunk[:200] + "..." if len(chunk) > 200 else chunk,
                            'path': file_path,
                            'doc_id': doc_id,
                            'chunk_id': i
                        })
                        all_doc_ids.append(doc_id)
                        
                except Exception as e:
                    print(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {file_info['file_path']}: {e}")
                    continue
            
            if not all_chunks:
                return
            
            # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±
            print(f"ğŸ§  {len(all_chunks)}ê°œ í…ìŠ¤íŠ¸ ì²­í¬ ì„ë² ë”© ìƒì„± ì¤‘...")
            vectors = embedder.encode_text_batch(all_chunks, batch_size=batch_size)
            
            # ë°°ì¹˜ë¡œ Qdrantì— ì¸ë±ì‹±
            print(f"ğŸ’¾ {len(vectors)}ê°œ ë²¡í„°ë¥¼ Qdrantì— ë°°ì¹˜ ì €ì¥ ì¤‘...")
            repo.index_text_chunks_batch(all_doc_ids, vectors, all_metas, batch_size)
            
        except Exception as e:
            print(f"í…ìŠ¤íŠ¸ íŒŒì¼ ë°°ì¹˜ ì¸ë±ì‹± ì˜¤ë¥˜: {e}")

    def _batch_index_image_files(self, image_files: List[Dict[str, Any]], repo: Repository, embedder: ColQwen2Embedder, batch_size: int):
        """ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ë°°ì¹˜ë¡œ ì¸ë±ì‹±"""
        try:
            all_images = []
            all_metas = []
            all_doc_ids = []
            
            # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘
            for file_info in image_files:
                try:
                    file_path = file_info['file_path']
                    from PIL import Image
                    
                    image = Image.open(file_path)
                    doc_id = f"file_{hash(file_path)}"
                    
                    all_images.append(image)
                    all_metas.append({
                        'bbox': [0, 0, image.width, image.height],
                        'path': file_path,
                        'image_size': f"{image.width}x{image.height}",
                        'doc_id': doc_id,
                        'patch_id': 0
                    })
                    all_doc_ids.append(doc_id)
                    
                except Exception as e:
                    print(f"ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {file_info['file_path']}: {e}")
                    continue
            
            if not all_images:
                return
            
            # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±
            print(f"ğŸ–¼ï¸ {len(all_images)}ê°œ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì¤‘...")
            vectors = embedder.encode_image_batch(all_images, batch_size=batch_size)
            
            # ë°°ì¹˜ë¡œ Qdrantì— ì¸ë±ì‹±
            print(f"ğŸ’¾ {len(vectors)}ê°œ ë²¡í„°ë¥¼ Qdrantì— ë°°ì¹˜ ì €ì¥ ì¤‘...")
            repo.index_image_patches_batch(all_doc_ids, vectors, all_metas, batch_size)
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ íŒŒì¼ ë°°ì¹˜ ì¸ë±ì‹± ì˜¤ë¥˜: {e}")

    def _index_file_for_rag(self, file_info: Dict[str, Any], repo: Repository, embedder: ColQwen2Embedder):
        """íŒŒì¼ì„ RAG ì‹œìŠ¤í…œì— ì¸ë±ì‹±"""
        try:
            file_path = file_info['file_path']
            file_category = file_info['file_category']
            
            # 1. SQLite ë©”íƒ€ë°ì´í„°ì— ì €ì¥
            doc_id = f"file_{hash(file_path)}"
            repo.sqlite.upsert_file(
                doc_id=doc_id,
                path=file_path,
                mime=self._get_mime_type(file_path),
                size=file_info['file_size'],
                created_at=int(file_info['created_date'].timestamp()),
                updated_at=int(file_info['modified_date'].timestamp()),
                accessed_at=int(file_info['accessed_date'].timestamp()),
                category=file_category,
                preview=self._get_file_preview(file_path)
            )
            
            # 2. íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ë²¡í„°í™” ë° ì¸ë±ì‹±
            if file_category in ['document', 'spreadsheet', 'presentation', 'code']:
                # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
                self._index_text_file(file_path, doc_id, repo, embedder)
            elif file_category == 'image':
                # ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬
                self._index_image_file(file_path, doc_id, repo, embedder)
                
        except Exception as e:
            print(f"RAG ì¸ë±ì‹± ì˜¤ë¥˜ {file_path}: {e}")

    def _index_text_file(self, file_path: str, doc_id: str, repo: Repository, embedder: ColQwen2Embedder):
        """í…ìŠ¤íŠ¸ íŒŒì¼ì„ RAG ì‹œìŠ¤í…œì— ì¸ë±ì‹±"""
        try:
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            content = self._extract_text_content(file_path)
            if not content:
                return
            
            # í…ìŠ¤íŠ¸ ì²­í‚¹
            chunks = self._chunk_text(content, chunk_size=1000)
            
            for i, chunk in enumerate(chunks):
                # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
                vectors = embedder.encode_text(chunk)
                
                # ë©”íƒ€ë°ì´í„° ìƒì„±
                meta = {
                    'page': i + 1,
                    'snippet': chunk[:200] + "..." if len(chunk) > 200 else chunk,
                    'path': file_path
                }
                
                # Qdrantì— ì¸ë±ì‹±
                repo.index_text_chunks(doc_id, vectors, [meta])
                
        except Exception as e:
            print(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì¸ë±ì‹± ì˜¤ë¥˜ {file_path}: {e}")

    def _index_image_file(self, file_path: str, doc_id: str, repo: Repository, embedder: ColQwen2Embedder):
        """ì´ë¯¸ì§€ íŒŒì¼ì„ RAG ì‹œìŠ¤í…œì— ì¸ë±ì‹±"""
        try:
            from PIL import Image
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(file_path)
            
            # ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±
            vectors = embedder.encode_image_patches(image)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            meta = {
                'bbox': [0, 0, image.width, image.height],
                'path': file_path,
                'image_size': f"{image.width}x{image.height}"
            }
            
            # Qdrantì— ì¸ë±ì‹±
            repo.index_image_patches(doc_id, vectors, [meta])
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ íŒŒì¼ ì¸ë±ì‹± ì˜¤ë¥˜ {file_path}: {e}")

    def _extract_text_content(self, file_path: str) -> str:
        """íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œ"""
        try:
            ext = Path(file_path).suffix.lower()
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì§ì ‘ ì½ê¸°
            if ext in ['.txt', '.py', '.js', '.html', '.css', '.md', '.json', '.xml', '.csv']:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read()
            
            # PDF íŒŒì¼ ì²˜ë¦¬
            elif ext == '.pdf':
                try:
                    import PyPDF2
                    with open(file_path, 'rb') as f:
                        pdf_reader = PyPDF2.PdfReader(f)
                        text = ""
                        for page in pdf_reader.pages:
                            text += page.extract_text() + "\n"
                        return text
                except ImportError:
                    print("PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                    return ""
            
            # Word ë¬¸ì„œ ì²˜ë¦¬
            elif ext in ['.docx', '.doc']:
                try:
                    from docx import Document
                    doc = Document(file_path)
                    text = ""
                    for paragraph in doc.paragraphs:
                        text += paragraph.text + "\n"
                    return text
                except ImportError:
                    print("python-docxê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Word íŒŒì¼ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                    return ""
            
            # Excel íŒŒì¼ ì²˜ë¦¬
            elif ext in ['.xlsx', '.xls']:
                try:
                    import pandas as pd
                    df = pd.read_excel(file_path)
                    return df.to_string()
                except ImportError:
                    print("pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Excel íŒŒì¼ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                    return ""
            
            return ""
            
        except Exception as e:
            print(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜ {file_path}: {e}")
            return ""

    def _chunk_text(self, text: str, chunk_size: int = 1000) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        chunks = []
        for i in range(0, len(text), chunk_size):
            chunk = text[i:i + chunk_size]
            if chunk.strip():
                chunks.append(chunk)
        return chunks

    def _get_mime_type(self, file_path: str) -> str:
        """íŒŒì¼ì˜ MIME íƒ€ì…ì„ ë°˜í™˜"""
        import mimetypes
        return mimetypes.guess_type(file_path)[0] or 'application/octet-stream'

    def _get_file_preview(self, file_path: str) -> str:
        """íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° ìƒì„±"""
        try:
            content = self._extract_text_content(file_path)
            if content:
                return content[:500] + "..." if len(content) > 500 else content
        except:
            pass
        return ""

# -----------------------------------------------------------------------------
# ì•„ë˜ì˜ ë‹¤ë¥¸ Collector ë° Manager í´ë˜ìŠ¤ë“¤ì€ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.
# -----------------------------------------------------------------------------

class BrowserHistoryCollector:
    # ... (ë³€ê²½ ì—†ìŒ)
    """ë¸Œë¼ìš°ì € ì‚¬ìš© ê¸°ë¡ì„ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, user_id: int):
        self.user_id = user_id
        self.sqlite_meta = SQLiteMeta()
        # ìš´ì˜ì²´ì œë³„ ë¸Œë¼ìš°ì € ê²½ë¡œ ì„¤ì •
        if platform.system() == "Windows":
            self.browser_paths = {
                'chrome': {
                    'path': os.path.expanduser('~\\AppData\\Local\\Google\\Chrome\\User Data\\Default\\History'),
                    'name': 'Chrome'
                },
                'edge': {
                    'path': os.path.expanduser('~\\AppData\\Local\\Microsoft\\Edge\\User Data\\Default\\History'),
                    'name': 'Edge'
                }
            }
        elif platform.system() == "Darwin":  # macOS
            self.browser_paths = {
                'chrome': {
                    'path': os.path.expanduser('~/Library/Application Support/Google/Chrome/Default/History'),
                    'name': 'Chrome'
                },
                'edge': {
                    'path': os.path.expanduser('~/Library/Application Support/Microsoft Edge/Default/History'),
                    'name': 'Edge'
                },
                'safari': {
                    'path': os.path.expanduser('~/Library/Safari/History.db'),
                    'name': 'Safari'
                }
            }
        else:  # Linux
            self.browser_paths = {
                'chrome': {
                    'path': os.path.expanduser('~/.config/google-chrome/Default/History'),
                    'name': 'Chrome'
                },
                'firefox': {
                    'path': os.path.expanduser('~/.mozilla/firefox/*/places.sqlite'),
                    'name': 'Firefox'
                }
            }
        # ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ìºì‹œ (ì¤‘ë³µ ë°©ì§€ìš©)
        self.history_cache = set()
    
    def get_chrome_history(self, incremental: bool = True) -> List[Dict[str, Any]]:
        """Chrome ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        history_data = []
        
        try:
            chrome_path = self.browser_paths['chrome']['path']
            if not os.path.exists(chrome_path):
                return history_data
            
            # Chrome íˆìŠ¤í† ë¦¬ íŒŒì¼ ë³µì‚¬ (ì‚¬ìš© ì¤‘ì¸ íŒŒì¼ì´ë¯€ë¡œ)
            import shutil
            temp_path = f"{chrome_path}_temp"
            shutil.copy2(chrome_path, temp_path)
            
            conn = sqlite3.connect(temp_path)
            cursor = conn.cursor()
            
            # ì¦ë¶„ ìˆ˜ì§‘ì„ ìœ„í•´ ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œê°„ ì´í›„ì˜ íˆìŠ¤í† ë¦¬ë§Œ ê°€ì ¸ì˜¤ê¸°
            if incremental:
                last_collection_time = self.sqlite_meta.get_last_browser_collection_time(self.user_id, 'Chrome')
                if last_collection_time:
                    # Chrome ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    chrome_timestamp = int((last_collection_time - datetime(1601, 1, 1)).total_seconds() * 1000000)
                    cursor.execute("""
                        SELECT url, title, visit_count, last_visit_time, typed_count
                        FROM urls 
                        WHERE last_visit_time > ?
                        ORDER BY last_visit_time DESC LIMIT 1000
                    """, (chrome_timestamp,))
                else:
                    cursor.execute("""
                        SELECT url, title, visit_count, last_visit_time, typed_count
                        FROM urls ORDER BY last_visit_time DESC LIMIT 1000
                    """)
            else:
                cursor.execute("""
                    SELECT url, title, visit_count, last_visit_time, typed_count
                    FROM urls ORDER BY last_visit_time DESC LIMIT 1000
                """)
            
            for row in cursor.fetchall():
                url, title, visit_count, last_visit_time, typed_count = row
                
                # Chrome ì‹œê°„ì„ datetimeìœ¼ë¡œ ë³€í™˜
                chrome_time = datetime(1601, 1, 1) + timedelta(microseconds=last_visit_time)
                
                # ì¤‘ë³µ ì²´í¬ (URL + ë°©ë¬¸ ì‹œê°„ ì¡°í•©)
                history_key = f"{url}_{chrome_time.timestamp()}"
                if history_key in self.history_cache:
                    continue
                
                # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¤‘ë³µ í™•ì¸
                if self.sqlite_meta.is_browser_history_duplicate(self.user_id, url, chrome_time):
                    continue
                
                self.history_cache.add(history_key)
                
                history_data.append({
                    'user_id': self.user_id,
                    'browser_name': 'Chrome',
                    'browser_version': self.get_chrome_version(),
                    'url': url,
                    'title': title,
                    'visit_count': visit_count,
                    'visit_time': chrome_time,
                    'last_visit_time': chrome_time,
                    'page_transition': 'typed' if typed_count > 0 else 'link',
                    'recorded_at': datetime.utcnow()
                })
            
            conn.close()
            os.remove(temp_path)
            
        except Exception as e:
            print(f"Chrome íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            
        return history_data
    
    def get_chrome_version(self) -> str:
        """Chrome ë²„ì „ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            if platform.system() == "Windows" and winreg is not None:
                key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, 
                                    r"Software\Google\Chrome\BLBeacon")
                version, _ = winreg.QueryValueEx(key, "version")
                return version
            elif platform.system() == "Darwin":  # macOS
                plist_path = "/Applications/Google Chrome.app/Contents/Info.plist"
                if os.path.exists(plist_path):
                    with open(plist_path, 'rb') as f:
                        plist_data = plistlib.load(f)
                        return plist_data.get('CFBundleShortVersionString', 'Unknown')
                else:
                    return "Chrome not installed"
            else:  # Linux
                try:
                    result = subprocess.run(['google-chrome', '--version'], 
                                          capture_output=True, text=True, timeout=5)
                    if result.returncode == 0:
                        return result.stdout.strip().split()[-1]
                except:
                    pass
                return "Unknown"
        except:
            return "Unknown"
    
    def get_edge_history(self, incremental: bool = True) -> List[Dict[str, Any]]:
        """Edge ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        history_data = []
        
        try:
            edge_path = self.browser_paths['edge']['path']
            if not os.path.exists(edge_path):
                return history_data
            
            # Edge íˆìŠ¤í† ë¦¬ íŒŒì¼ ë³µì‚¬ (ì‚¬ìš© ì¤‘ì¸ íŒŒì¼ì´ë¯€ë¡œ)
            import shutil
            temp_path = f"{edge_path}_temp"
            shutil.copy2(edge_path, temp_path)
            
            conn = sqlite3.connect(temp_path)
            cursor = conn.cursor()
            
            # ì¦ë¶„ ìˆ˜ì§‘ì„ ìœ„í•´ ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œê°„ ì´í›„ì˜ íˆìŠ¤í† ë¦¬ë§Œ ê°€ì ¸ì˜¤ê¸°
            if incremental:
                last_collection_time = self.sqlite_meta.get_last_browser_collection_time(self.user_id, 'Edge')
                if last_collection_time:
                    # Edge ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (Chromeê³¼ ë™ì¼í•œ í˜•ì‹)
                    edge_timestamp = int((last_collection_time - datetime(1601, 1, 1)).total_seconds() * 1000000)
                    cursor.execute("""
                        SELECT url, title, visit_count, last_visit_time, typed_count
                        FROM urls 
                        WHERE last_visit_time > ?
                        ORDER BY last_visit_time DESC LIMIT 1000
                    """, (edge_timestamp,))
                else:
                    cursor.execute("""
                        SELECT url, title, visit_count, last_visit_time, typed_count
                        FROM urls ORDER BY last_visit_time DESC LIMIT 1000
                    """)
            else:
                cursor.execute("""
                    SELECT url, title, visit_count, last_visit_time, typed_count
                    FROM urls ORDER BY last_visit_time DESC LIMIT 1000
                """)
            
            for row in cursor.fetchall():
                url, title, visit_count, last_visit_time, typed_count = row
                
                # Edge ì‹œê°„ì„ datetimeìœ¼ë¡œ ë³€í™˜ (Chromeê³¼ ë™ì¼í•œ í˜•ì‹)
                edge_time = datetime(1601, 1, 1) + timedelta(microseconds=last_visit_time)
                
                # ì¤‘ë³µ ì²´í¬ (URL + ë°©ë¬¸ ì‹œê°„ ì¡°í•©)
                history_key = f"{url}_{edge_time.timestamp()}"
                if history_key in self.history_cache:
                    continue
                
                # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¤‘ë³µ í™•ì¸
                if self.sqlite_meta.is_browser_history_duplicate(self.user_id, url, edge_time):
                    continue
                
                self.history_cache.add(history_key)
                
                history_data.append({
                    'user_id': self.user_id,
                    'browser_name': 'Edge',
                    'browser_version': self.get_edge_version(),
                    'url': url,
                    'title': title,
                    'visit_count': visit_count,
                    'visit_time': edge_time,
                    'last_visit_time': edge_time,
                    'page_transition': 'typed' if typed_count > 0 else 'link',
                    'recorded_at': datetime.utcnow()
                })
            
            conn.close()
            os.remove(temp_path)
            
        except Exception as e:
            print(f"Edge íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            
        return history_data
    
    def get_edge_version(self) -> str:
        """Edge ë²„ì „ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            if platform.system() == "Windows" and winreg is not None:
                key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, 
                                    r"Software\Microsoft\Edge\BLBeacon")
                version, _ = winreg.QueryValueEx(key, "version")
                return version
            elif platform.system() == "Darwin":  # macOS
                plist_path = "/Applications/Microsoft Edge.app/Contents/Info.plist"
                if os.path.exists(plist_path):
                    with open(plist_path, 'rb') as f:
                        plist_data = plistlib.load(f)
                        return plist_data.get('CFBundleShortVersionString', 'Unknown')
                else:
                    return "Edge not installed"
            else:  # Linux
                try:
                    result = subprocess.run(['microsoft-edge', '--version'], 
                                          capture_output=True, text=True, timeout=5)
                    if result.returncode == 0:
                        return result.stdout.strip().split()[-1]
                except:
                    pass
                return "Unknown"
        except:
            return "Unknown"
    
    def collect_all_browser_history(self, incremental: bool = True) -> List[Dict[str, Any]]:
        """ëª¨ë“  ë¸Œë¼ìš°ì €ì˜ íˆìŠ¤í† ë¦¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        all_history = []
        
        # Chrome íˆìŠ¤í† ë¦¬
        chrome_history = self.get_chrome_history(incremental)
        all_history.extend(chrome_history)
        
        # Edge íˆìŠ¤í† ë¦¬
        edge_history = self.get_edge_history(incremental)
        all_history.extend(edge_history)
        
        return all_history
    
    def save_browser_history_to_db(self, history_data: List[Dict[str, Any]]) -> int:
        """ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê³  RAG ì‹œìŠ¤í…œì— ì¸ë±ì‹±í•©ë‹ˆë‹¤."""
        saved_count = 0
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        try:
            repo = Repository()
            embedder = ColQwen2Embedder()
        except Exception as e:
            print(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            repo = None
            embedder = None
        
        for history_item in history_data:
            try:
                # 1. SQLiteì— ì €ì¥
                success = self.sqlite_meta.insert_collected_browser_history(history_item)
                
                if success:
                    saved_count += 1
                    
                    # 2. RAG ì‹œìŠ¤í…œì— ì¸ë±ì‹±
                    if repo and embedder:
                        self._index_web_history_for_rag(history_item, repo, embedder)
                        
            except Exception as e:
                print(f"ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ì €ì¥ ì˜¤ë¥˜: {e}")
                continue
            
        return saved_count

    def _index_web_history_for_rag(self, history_item: Dict[str, Any], repo: Repository, embedder: ColQwen2Embedder):
        """ì›¹ íˆìŠ¤í† ë¦¬ë¥¼ RAG ì‹œìŠ¤í…œì— ì¸ë±ì‹±"""
        try:
            url = history_item['url']
            title = history_item['title']
            visit_time = history_item['visit_time']
            
            # 1. SQLite ë©”íƒ€ë°ì´í„°ì— ì €ì¥
            doc_id = f"web_{hash(url + str(visit_time))}"
            repo.sqlite.insert_web_history(
                url=url,
                title=title,
                visited_at=int(visit_time.timestamp()),
                visit_count=history_item.get('visit_count', 1),
                transition=history_item.get('page_transition', 'link'),
                browser=history_item.get('browser_name', 'Unknown'),
                version=history_item.get('browser_version', 'Unknown'),
                domain=self._extract_domain(url),
                duration_sec=0,  # ê¸°ë³¸ê°’
                tab_title=title
            )
            
            # 2. ì›¹ í˜ì´ì§€ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë²¡í„°í™”
            content = f"ì œëª©: {title}\nURL: {url}\në°©ë¬¸ ì‹œê°„: {visit_time}"
            
            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            vectors = embedder.encode_text(content)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            meta = {
                'url': url,
                'title': title,
                'visit_time': int(visit_time.timestamp()),
                'browser': history_item.get('browser_name', 'Unknown'),
                'domain': self._extract_domain(url)
            }
            
            # Qdrantì— ì¸ë±ì‹±
            repo.index_text_chunks(doc_id, vectors, [meta])
            
        except Exception as e:
            print(f"ì›¹ íˆìŠ¤í† ë¦¬ RAG ì¸ë±ì‹± ì˜¤ë¥˜: {e}")

    def _extract_domain(self, url: str) -> str:
        """URLì—ì„œ ë„ë©”ì¸ì„ ì¶”ì¶œ"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            return parsed.netloc
        except:
            return "unknown"

class ActiveApplicationCollector:
    # ... (ë³€ê²½ ì—†ìŒ)
    """ì‹¤í–‰ ì¤‘ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, user_id: int):
        self.user_id = user_id
        self.sqlite_meta = SQLiteMeta()
        self.app_categories = {
            'productivity': ['word', 'excel', 'powerpoint', 'outlook', 'notepad', 'wordpad'],
            'development': ['code', 'pycharm', 'intellij', 'eclipse', 'visual studio', 'sublime'],
            'browser': ['chrome', 'firefox', 'edge', 'safari', 'opera'],
            'entertainment': ['spotify', 'youtube', 'netflix', 'vlc', 'media player'],
            'communication': ['teams', 'zoom', 'skype', 'discord', 'slack'],
            'gaming': ['steam', 'origin', 'battle.net', 'epic games']
        }
    
    def get_app_category(self, app_name: str) -> str:
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        app_lower = app_name.lower()
        
        for category, apps in self.app_categories.items():
            if any(app in app_lower for app in apps):
                return category
        return 'other'
    
    def collect_active_applications(self) -> List[Dict[str, Any]]:
        """í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ë“¤ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        active_apps = []
        
        try:
            for proc in psutil.process_iter(['pid', 'name', 'exe', 'cpu_percent', 'memory_info', 'create_time']):
                try:
                    proc_info = proc.info
                    
                    if proc_info['exe'] and os.path.exists(proc_info['exe']):
                        app_info = {
                            'user_id': self.user_id,
                            'app_name': proc_info['name'],
                            'app_path': proc_info['exe'],
                            'app_version': self.get_app_version(proc_info['exe']),
                            'app_category': self.get_app_category(proc_info['name']),
                            'start_time': datetime.fromtimestamp(proc_info['create_time']),
                            'end_time': None,  # ì•„ì§ ì‹¤í–‰ ì¤‘
                            'duration': int(time.time() - proc_info['create_time']),
                            'cpu_usage': proc_info['cpu_percent'],
                            'memory_usage': proc_info['memory_info'].rss / 1024 / 1024,  # MB
                            'recorded_at': datetime.utcnow()
                        }
                        
                        active_apps.append(app_info)
                        
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    continue
                    
        except Exception as e:
            print(f"í™œì„± ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            
        return active_apps
    
    def get_app_version(self, exe_path: str) -> str:
        """ì‹¤í–‰ íŒŒì¼ì˜ ë²„ì „ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            if platform.system() == "Windows":
                import win32api
                info = win32api.GetFileVersionInfo(exe_path, "\\")
                ms = info['FileVersionMS']
                ls = info['FileVersionLS']
                version = f"{win32api.HIWORD(ms)}.{win32api.LOWORD(ms)}.{win32api.HIWORD(ls)}.{win32api.LOWORD(ls)}"
                return version
            elif platform.system() == "Darwin":  # macOS
                return self._get_app_version_macos(exe_path)
            else:  # Linux
                return self._get_app_version_linux(exe_path)
        except:
            return "Unknown"
    
    def _get_app_version_macos(self, app_path: str) -> str:
        """macOSì—ì„œ ì•± ë²„ì „ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            # .app ë²ˆë“¤ì¸ ê²½ìš° Info.plistì—ì„œ ë²„ì „ ì •ë³´ ì¶”ì¶œ
            if app_path.endswith('.app'):
                plist_path = os.path.join(app_path, 'Contents', 'Info.plist')
                if os.path.exists(plist_path):
                    with open(plist_path, 'rb') as f:
                        plist_data = plistlib.load(f)
                        return plist_data.get('CFBundleShortVersionString', 'Unknown')
            
            # ì¼ë°˜ ì‹¤í–‰íŒŒì¼ì¸ ê²½ìš° otool ëª…ë ¹ì–´ ì‚¬ìš©
            try:
                result = subprocess.run(['otool', '-L', app_path], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    # ë²„ì „ ì •ë³´ íŒŒì‹± ë¡œì§ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
                    return "1.0.0"  # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ íŒŒì‹± í•„ìš”
            except:
                pass
            
            return "Unknown"
        except:
            return "Unknown"
    
    def _get_app_version_linux(self, exe_path: str) -> str:
        """Linuxì—ì„œ ì•± ë²„ì „ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            # dpkgë¥¼ ì‚¬ìš©í•´ì„œ íŒ¨í‚¤ì§€ ë²„ì „ í™•ì¸ (Debian/Ubuntu)
            try:
                result = subprocess.run(['dpkg', '-S', exe_path], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    package_name = result.stdout.split(':')[0]
                    version_result = subprocess.run(['dpkg', '-l', package_name], 
                                                  capture_output=True, text=True, timeout=5)
                    if version_result.returncode == 0:
                        lines = version_result.stdout.split('\n')
                        for line in lines:
                            if package_name in line:
                                parts = line.split()
                                if len(parts) >= 3:
                                    return parts[2]
            except:
                pass
            
            # rpmì„ ì‚¬ìš©í•´ì„œ íŒ¨í‚¤ì§€ ë²„ì „ í™•ì¸ (Red Hat/CentOS)
            try:
                result = subprocess.run(['rpm', '-qf', exe_path], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    return result.stdout.strip()
            except:
                pass
            
            return "Unknown"
        except:
            return "Unknown"
    
    def save_active_apps_to_db(self, apps_data: List[Dict[str, Any]]) -> int:
        """í™œì„± ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
        saved_count = 0
        
        for app_data in apps_data:
            try:
                # SQLiteë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥
                if self.sqlite_meta.insert_collected_app(app_data):
                    saved_count += 1
                
            except Exception as e:
                print(f"í™œì„± ì• í”Œë¦¬ì¼€ì´ì…˜ ì €ì¥ ì˜¤ë¥˜: {e}")
                continue
            
        return saved_count

class ScreenActivityCollector:
    # ... (ë³€ê²½ ì—†ìŒ)
    """í™”ë©´ í™œë™ì„ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, user_id: int):
        self.user_id = user_id
        self.sqlite_meta = SQLiteMeta()
        self.screenshot_dir = Path("uploads/screenshots")
        # í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œë§Œ ìƒì„±
        if not self.screenshot_dir.exists():
            self.screenshot_dir.mkdir(parents=True, exist_ok=True)
        
        # LLM ì´ˆê¸°í™”
        self.llm = self._initialize_llm()
    
    def _initialize_llm(self):
        """LLMì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            if settings.GEMINI_API_KEY:
                import google.generativeai as genai
                genai.configure(api_key=settings.GEMINI_API_KEY)
                return genai.GenerativeModel(settings.GEMINI_MODEL)
            else:
                return None
        except Exception as e:
            print(f"LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            return None
    
    def capture_screenshot(self) -> Optional[Tuple[bytes, str]]:
        """í™”ë©´ ìŠ¤í¬ë¦°ìƒ·ì„ ìº¡ì²˜í•©ë‹ˆë‹¤."""
        try:
            # macOSì—ì„œëŠ” screencapture ëª…ë ¹ì–´ ì‚¬ìš©
            if platform.system() == "Darwin":
                return self._capture_screenshot_macos()
            # Windows/Linuxì—ì„œëŠ” PIL ImageGrab ì‚¬ìš©
            elif ImageGrab is not None:
                return self._capture_screenshot_pil()
            else:
                print("ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
        except Exception as e:
            print(f"ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ ì˜¤ë¥˜: {e}")
            return None
    
    def _capture_screenshot_macos(self) -> Optional[Tuple[bytes, str]]:
        """macOSì—ì„œ screencapture ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•´ ìŠ¤í¬ë¦°ìƒ·ì„ ìº¡ì²˜í•©ë‹ˆë‹¤."""
        try:
            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"screenshot_{self.user_id}_{timestamp}.png"
            file_path = self.screenshot_dir / filename
            
            # screencapture ëª…ë ¹ì–´ë¡œ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
            result = subprocess.run(['screencapture', '-x', str(file_path)], 
                                  capture_output=True, timeout=10)
            
            if result.returncode == 0 and os.path.exists(file_path):
                # íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ê¸°
                with open(file_path, 'rb') as f:
                    screenshot_data = f.read()
                return screenshot_data, str(file_path)
            else:
                print("screencapture ëª…ë ¹ì–´ ì‹¤í–‰ ì‹¤íŒ¨")
                return None
        except Exception as e:
            print(f"macOS ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ ì˜¤ë¥˜: {e}")
            return None
    
    def _capture_screenshot_pil(self) -> Optional[Tuple[bytes, str]]:
        """PIL ImageGrabì„ ì‚¬ìš©í•´ ìŠ¤í¬ë¦°ìƒ·ì„ ìº¡ì²˜í•©ë‹ˆë‹¤."""
        try:
            # ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
            screenshot = ImageGrab.grab()
            
            # íŒŒì¼ëª… ìƒì„± (ì˜ˆ: screenshot_1_20241201_143022.png)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"screenshot_{self.user_id}_{timestamp}.png"
            file_path = self.screenshot_dir / filename
            
            # ì´ë¯¸ì§€ë¥¼ uploads/screenshots/ ë””ë ‰í† ë¦¬ì— ì €ì¥
            screenshot.save(file_path, 'PNG')
            
            # ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì½ê¸°
            with open(file_path, 'rb') as f:
                image_data = f.read()
            
            return image_data, str(file_path)
            
        except Exception as e:
            print(f"PIL ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ ì˜¤ë¥˜: {e}")
            return None
    
    async def analyze_screenshot_with_llm(self, image_data: bytes) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤í¬ë¦°ìƒ·ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            if not self.llm:
                return self._fallback_analysis()
            
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            import base64
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"""
ë‹¤ìŒ ìŠ¤í¬ë¦°ìƒ·ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìê°€ í˜„ì¬ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "activity_description": "ì‚¬ìš©ìê°€ í˜„ì¬ í•˜ê³  ìˆëŠ” í™œë™ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…",
    "activity_category": "ì‘ì—…, ë¸Œë¼ìš°ì§•, ì—”í„°í…Œì¸ë¨¼íŠ¸, ê°œë°œ, í†µì‹  ì¤‘ í•˜ë‚˜",
    "activity_confidence": 0.95,
    "detected_apps": ["ê°ì§€ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ëª©ë¡"],
    "detected_text": ["í™”ë©´ì—ì„œ ê°ì§€ëœ ì£¼ìš” í…ìŠ¤íŠ¸ë“¤"],
    "detected_objects": ["í™”ë©´ì—ì„œ ê°ì§€ëœ ì£¼ìš” ê°ì²´ë“¤"]
}}

ìŠ¤í¬ë¦°ìƒ·: data:image/png;base64,{image_base64}

JSON ì‘ë‹µë§Œ ì œê³µí•´ì£¼ì„¸ìš”:
"""
            
            # LLM í˜¸ì¶œ
            response = self.llm.generate_content(prompt)
            analysis_text = response.text
            
            # JSON íŒŒì‹±
            import json
            import re
            
            json_match = re.search(r'\{.*\}', analysis_text, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group())
                return analysis
            else:
                return self._fallback_analysis()
                
        except Exception as e:
            print(f"LLM ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._fallback_analysis()
    
    def _fallback_analysis(self) -> Dict[str, Any]:
        """LLMì´ ì—†ì„ ë•Œì˜ ê¸°ë³¸ ë¶„ì„"""
        return {
            "activity_description": "ìŠ¤í¬ë¦°ìƒ·ì´ ìº¡ì²˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "activity_category": "unknown",
            "activity_confidence": 0.5,
            "detected_apps": [],
            "detected_text": [],
            "detected_objects": []
        }
    
    def save_screen_activity_to_db(self, screenshot_data: bytes, file_path: str, 
                                 analysis: Dict[str, Any]) -> bool:
        """í™”ë©´ í™œë™ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê³  RAG ì‹œìŠ¤í…œì— ì¸ë±ì‹±í•©ë‹ˆë‹¤."""
        try:
            # í™”ë©´ í•´ìƒë„ ê°€ì ¸ì˜¤ê¸°
            screen = ImageGrab.grab()
            resolution = f"{screen.width}x{screen.height}"
            
            # SQLiteì— ì €ì¥
            screenshot_info = {
                'user_id': self.user_id,
                'screenshot_path': file_path,
                'screenshot_data': screenshot_data,
                'activity_description': analysis.get('activity_description', ''),
                'activity_category': analysis.get('activity_category', ''),
                'activity_confidence': analysis.get('activity_confidence', 0.0),
                'detected_apps': analysis.get('detected_apps', []),
                'detected_text': analysis.get('detected_text', []),
                'detected_objects': analysis.get('detected_objects', []),
                'screen_resolution': resolution,
                'color_mode': 'light'
            }
            
            success = self.sqlite_meta.insert_collected_screenshot(screenshot_info)
            
            if success:
                # RAG ì‹œìŠ¤í…œì— ì¸ë±ì‹±
                self._index_screen_activity_for_rag(screenshot_data, file_path, analysis)
            
            return success
            
        except Exception as e:
            print(f"í™”ë©´ í™œë™ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False

    def _index_screen_activity_for_rag(self, screenshot_data: bytes, file_path: str, analysis: Dict[str, Any]):
        """í™”ë©´ í™œë™ì„ RAG ì‹œìŠ¤í…œì— ì¸ë±ì‹±"""
        try:
            # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            repo = Repository()
            embedder = ColQwen2Embedder()
            
            # 1. SQLite ë©”íƒ€ë°ì´í„°ì— ì €ì¥
            doc_id = f"screen_{hash(file_path)}"
            repo.sqlite.insert_screenshot(
                doc_id=doc_id,
                path=file_path,
                captured_at=int(datetime.utcnow().timestamp()),
                app_name=analysis.get('detected_apps', ['Unknown'])[0] if analysis.get('detected_apps') else 'Unknown',
                window_title=analysis.get('activity_description', ''),
                hash=hashlib.md5(screenshot_data).hexdigest(),
                ocr="",  # OCR ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€
                gemini_desc=analysis.get('activity_description', ''),
                category=analysis.get('activity_category', 'unknown'),
                confidence=analysis.get('activity_confidence', 0.0)
            )
            
            # 2. ìŠ¤í¬ë¦°ìƒ· ì´ë¯¸ì§€ ë²¡í„°í™”
            from PIL import Image
            import io
            
            # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ PIL Imageë¡œ ë³€í™˜
            image = Image.open(io.BytesIO(screenshot_data))
            
            # ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±
            vectors = embedder.encode_image_patches(image)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            meta = {
                'bbox': [0, 0, image.width, image.height],
                'path': file_path,
                'app_name': analysis.get('detected_apps', ['Unknown'])[0] if analysis.get('detected_apps') else 'Unknown',
                'activity_description': analysis.get('activity_description', ''),
                'activity_category': analysis.get('activity_category', 'unknown'),
                'detected_text': analysis.get('detected_text', [])
            }
            
            # Qdrantì— ì¸ë±ì‹±
            repo.index_screen_patches(doc_id, vectors, [meta])
            
        except Exception as e:
            print(f"í™”ë©´ í™œë™ RAG ì¸ë±ì‹± ì˜¤ë¥˜: {e}")

class DataCollectionManager:
    # ... (ë³€ê²½ ì—†ìŒ)
    """ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, user_id: int):
        self.user_id = user_id
        self.file_collector = FileCollector(user_id)
        self.browser_collector = BrowserHistoryCollector(user_id)
        self.app_collector = ActiveApplicationCollector(user_id)
        self.screen_collector = ScreenActivityCollector(user_id)
        
        self.running = False
        self.collection_thread = None
        self.initial_collection_done = False
        
        # ì§„í–‰ë¥  ì¶”ì ìš© ì†ì„± ì¶”ê°€
        self.progress = 0.0
        self.progress_message = "ì´ˆê¸°í™” ì¤‘..."
        
        # ì„ íƒëœ í´ë” ëª©ë¡
        self.selected_folders = None
        
        # í´ë” ì„ íƒ ìƒíƒœ ê´€ë¦¬
        self.folders_selected = False  # ì‚¬ìš©ìê°€ í´ë”ë¥¼ ì„ íƒí–ˆëŠ”ì§€ ì—¬ë¶€
        self.waiting_for_folder_selection = True  # í´ë” ì„ íƒì„ ê¸°ë‹¤ë¦¬ê³  ìˆëŠ”ì§€ ì—¬ë¶€
    
    def start_collection(self, selected_folders: Optional[List[str]] = None):
        """ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
        if self.running:
            return
        
        # ì„ íƒëœ í´ë” ì„¤ì •
        self.selected_folders = selected_folders
        
        # í´ë” ì„ íƒ ìƒíƒœ ì—…ë°ì´íŠ¸
        if selected_folders is not None:
            self.folders_selected = True
            self.waiting_for_folder_selection = False
            print(f"í´ë” ì„ íƒ ì™„ë£Œ: {len(selected_folders)}ê°œ í´ë”")
        else:
            # selected_foldersê°€ Noneì´ë©´ ì „ì²´ Cë“œë¼ì´ë¸Œ ìŠ¤ìº”ì„ ì˜ë¯¸
            self.folders_selected = True
            self.waiting_for_folder_selection = False
            print("ì „ì²´ Cë“œë¼ì´ë¸Œ ìŠ¤ìº” ëª¨ë“œë¡œ ì„¤ì •")
        
        # ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ìˆ˜í–‰ (í´ë”ê°€ ì„ íƒëœ ê²½ìš°ì—ë§Œ)
        if not self.initial_collection_done and self.folders_selected:
            self.perform_initial_collection()
        
        self.running = True
        self.collection_thread = threading.Thread(target=self._collection_loop)
        self.collection_thread.daemon = True
        self.collection_thread.start()
        
        folder_info = f" (ì„ íƒëœ í´ë”: {len(selected_folders)}ê°œ)" if selected_folders else " (ì „ì²´ Cë“œë¼ì´ë¸Œ)"
        print(f"ì‚¬ìš©ì {self.user_id}ì˜ ë°ì´í„° ìˆ˜ì§‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤{folder_info}.")
    
    def perform_initial_collection(self):
        """í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        print(f"ì‚¬ìš©ì {self.user_id}ì˜ ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        try:
            # 1. íŒŒì¼ ìˆ˜ì§‘ (ì „ì²´ ìˆ˜ì§‘) - ì „ì²´ ì§„í–‰ë¥ ì˜ 80% í• ë‹¹
            self.progress_message = "ğŸ“ ì´ˆê¸° íŒŒì¼ ìˆ˜ì§‘ ì¤‘..."
            print(self.progress_message)
            # manager ì¸ìŠ¤í„´ìŠ¤(self)ë¥¼ ì „ë‹¬í•˜ì—¬ ì§„í–‰ë¥ ì„ ì—…ë°ì´íŠ¸í•˜ë„ë¡ í•¨
            files = self.file_collector.collect_files_from_drive(incremental=False, manager=self, selected_folders=self.selected_folders)
            
            # 2. ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ (ì „ì²´ ì§„í–‰ë¥ ì˜ 15% í• ë‹¹)
            self.progress = 80.0
            self.progress_message = "ğŸŒ ì´ˆê¸° ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ ì¤‘..."
            print(self.progress_message)
            history = self.browser_collector.collect_all_browser_history(incremental=False)
            
            # 3. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ (ì „ì²´ ì§„í–‰ë¥ ì˜ 5% í• ë‹¹)
            self.progress = 95.0
            self.progress_message = "ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘..."
            print(self.progress_message)
            saved_files = self.file_collector.save_files_to_db(files)
            print(f"âœ… íŒŒì¼ ìˆ˜ì§‘ ì™„ë£Œ: {saved_files}ê°œ ì €ì¥")
            saved_history = self.browser_collector.save_browser_history_to_db(history)
            print(f"âœ… ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ ì™„ë£Œ: {saved_history}ê°œ ì €ì¥")
            
            self.progress = 100.0
            self.progress_message = "ğŸ‰ ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!"
            print(self.progress_message)
            
        except Exception as e:
            print(f"âŒ ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.progress_message = "ì˜¤ë¥˜ ë°œìƒ"
        finally:
            # ì™„ë£Œ í”Œë˜ê·¸ë¥¼ ë§ˆì§€ë§‰ì— ì„¤ì •
            self.initial_collection_done = True
    
    def stop_collection(self):
        """ë°ì´í„° ìˆ˜ì§‘ì„ ì¤‘ì§€í•©ë‹ˆë‹¤."""
        self.running = False
        if self.collection_thread:
            self.collection_thread.join()
        print(f"ì‚¬ìš©ì {self.user_id}ì˜ ë°ì´í„° ìˆ˜ì§‘ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _collection_loop(self):
        """ë°ì´í„° ìˆ˜ì§‘ ë£¨í”„"""
        last_file_collection = 0
        last_browser_collection = 0
        last_app_collection = 0
        last_screen_collection = 0
        
        while self.running:
            try:
                current_time = time.time()
                
                # íŒŒì¼ ìˆ˜ì§‘ (1ì‹œê°„ë§ˆë‹¤) - í´ë”ê°€ ì„ íƒëœ ê²½ìš°ì—ë§Œ
                if current_time - last_file_collection >= 3600 and self.folders_selected:
                    self._collect_files()
                    last_file_collection = current_time
                elif not self.folders_selected and self.waiting_for_folder_selection:
                    # í´ë” ì„ íƒì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì´ë©´ ë©”ì‹œì§€ ì¶œë ¥ (ìµœì´ˆ 1íšŒë§Œ)
                    if last_file_collection == 0:
                        print("í´ë” ì„ íƒì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì…ë‹ˆë‹¤. ìš°í´ë¦­ â†’ 'í´ë” ì„ íƒ'ì„ í†µí•´ ìˆ˜ì§‘í•  í´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
                        last_file_collection = current_time  # ë©”ì‹œì§€ ì¤‘ë³µ ì¶œë ¥ ë°©ì§€
                
                # ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ (30ë¶„ë§ˆë‹¤)
                if current_time - last_browser_collection >= 1800:
                    self._collect_browser_history()
                    last_browser_collection = current_time
                
                # í™œì„± ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ì§‘ (5ë¶„ë§ˆë‹¤)
                if current_time - last_app_collection >= 300:
                    self._collect_active_apps()
                    last_app_collection = current_time
                
                # í™”ë©´ í™œë™ ìˆ˜ì§‘ (1ë¶„ë§ˆë‹¤)
                if current_time - last_screen_collection >= 60:
                    self._collect_screen_activity()
                    last_screen_collection = current_time
                
                time.sleep(10)  # 10ì´ˆë§ˆë‹¤ ì²´í¬
                
            except Exception as e:
                print(f"ë°ì´í„° ìˆ˜ì§‘ ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(30)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ 30ì´ˆ ëŒ€ê¸°
    
    def _collect_files(self):
        """íŒŒì¼ ìˆ˜ì§‘ (ì¦ë¶„ ìˆ˜ì§‘)"""
        try:
            print("íŒŒì¼ ìˆ˜ì§‘ ì‹œì‘...")
            files = self.file_collector.collect_files_from_drive(incremental=True, selected_folders=self.selected_folders)
            saved_count = self.file_collector.save_files_to_db(files)
            print(f"íŒŒì¼ ìˆ˜ì§‘ ì™„ë£Œ: {saved_count}ê°œ ì €ì¥")
        except Exception as e:
            print(f"íŒŒì¼ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
    
    def _collect_browser_history(self):
        """ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ (ì¦ë¶„ ìˆ˜ì§‘)"""
        try:
            print("ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ ì‹œì‘...")
            history = self.browser_collector.collect_all_browser_history(incremental=True)
            saved_count = self.browser_collector.save_browser_history_to_db(history)
            print(f"ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ ì™„ë£Œ: {saved_count}ê°œ ì €ì¥")
        except Exception as e:
            print(f"ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
    
    def _collect_active_apps(self):
        """í™œì„± ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ì§‘"""
        try:
            print("í™œì„± ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ì§‘ ì‹œì‘...")
            apps = self.app_collector.collect_active_applications()
            saved_count = self.app_collector.save_active_apps_to_db(apps)
            print(f"í™œì„± ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ì§‘ ì™„ë£Œ: {saved_count}ê°œ ì €ì¥")
        except Exception as e:
            print(f"í™œì„± ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
    
    def _collect_screen_activity(self):
        """í™”ë©´ í™œë™ ìˆ˜ì§‘"""
        try:
            print("í™”ë©´ í™œë™ ìˆ˜ì§‘ ì‹œì‘...")
            
            # ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
            screenshot_result = self.screen_collector.capture_screenshot()
            if screenshot_result:
                image_data, file_path = screenshot_result
                
                # LLM ë¶„ì„ (ë¹„ë™ê¸°ë¡œ ì‹¤í–‰)
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                analysis = loop.run_until_complete(
                    self.screen_collector.analyze_screenshot_with_llm(image_data)
                )
                loop.close()
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                success = self.screen_collector.save_screen_activity_to_db(
                    image_data, file_path, analysis
                )
                
                if success:
                    print(f"í™”ë©´ í™œë™ ìˆ˜ì§‘ ì™„ë£Œ: {analysis.get('activity_category', 'unknown')}")
                else:
                    print("í™”ë©´ í™œë™ ì €ì¥ ì‹¤íŒ¨")
            else:
                print("ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"í™”ë©´ í™œë™ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

# ì „ì—­ ë°ì´í„° ìˆ˜ì§‘ ê´€ë¦¬ìë“¤
data_collection_managers = {}

def start_user_data_collection(user_id: int, selected_folders: Optional[List[str]] = None):
    """ì‚¬ìš©ì ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
    if user_id not in data_collection_managers:
        manager = DataCollectionManager(user_id)
        data_collection_managers[user_id] = manager
        
        # í´ë” ì„ íƒì´ ìˆìœ¼ë©´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘, ì—†ìœ¼ë©´ ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •
        if selected_folders is not None:
            manager.start_collection(selected_folders)
        else:
            # í´ë” ì„ íƒ ì—†ì´ í˜¸ì¶œëœ ê²½ìš°, ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì •
            manager.running = True
            manager.collection_thread = threading.Thread(target=manager._collection_loop)
            manager.collection_thread.daemon = True
            manager.collection_thread.start()
            print(f"ì‚¬ìš©ì {user_id}ì˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œì´ ëŒ€ê¸° ìƒíƒœë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("í´ë” ì„ íƒì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì…ë‹ˆë‹¤. ìš°í´ë¦­ â†’ 'í´ë” ì„ íƒ'ì„ í†µí•´ ìˆ˜ì§‘í•  í´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
    else:
        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš°, í´ë” ì„ íƒì´ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
        manager = data_collection_managers[user_id]
        if selected_folders is not None:
            manager.start_collection(selected_folders)
        else:
            print(f"ì‚¬ìš©ì {user_id}ì˜ ë°ì´í„° ìˆ˜ì§‘ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")

def stop_user_data_collection(user_id: int):
    """ì‚¬ìš©ì ë°ì´í„° ìˆ˜ì§‘ì„ ì¤‘ì§€í•©ë‹ˆë‹¤."""
    if user_id in data_collection_managers:
        data_collection_managers[user_id].stop_collection()
        del data_collection_managers[user_id]

def stop_all_data_collection():
    """ëª¨ë“  ì‚¬ìš©ìì˜ ë°ì´í„° ìˆ˜ì§‘ì„ ì¤‘ì§€í•©ë‹ˆë‹¤."""
    for user_id in list(data_collection_managers.keys()):
        stop_user_data_collection(user_id)