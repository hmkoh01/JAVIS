import os
import sys
from pathlib import Path

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬(backend)ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
backend_dir = Path(__file__).parent.parent.absolute()
if str(backend_dir) not in sys.path:
    sys.path.insert(0, str(backend_dir))

from typing import Dict, Any, Optional, List, Annotated, Sequence, TypedDict, TYPE_CHECKING
from pydantic import BaseModel
from langchain_community.chat_models import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage
from langgraph.graph import StateGraph
from langgraph.constants import START, END
from langgraph.graph.message import add_messages
import google.generativeai as genai
from config.settings import settings
from core.agent_registry import agent_registry
from agents.base_agent import AgentResponse

if TYPE_CHECKING:
    from agents.base_agent import BaseAgent
else:
    BaseAgent = None

class UserIntent(BaseModel):
    """ì‚¬ìš©ì ì˜ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ëª¨ë¸"""
    user_id: Optional[int] = None
    message: str
    context: Dict[str, Any] = {}

class SupervisorResponse(BaseModel):
    """Supervisor ì‘ë‹µì„ ë‚˜íƒ€ë‚´ëŠ” ëª¨ë¸"""
    success: bool
    selected_agent: str
    response: AgentResponse
    reasoning: str
    metadata: Dict[str, Any] = {}

class AgentState(TypedDict):
    """LangGraph ìƒíƒœ ì •ì˜"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    user_input: str
    user_id: Optional[int]
    user_context: Dict[str, Any]
    selected_agents: List[str]  # ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ì§€ì›
    reasoning: str
    agent_responses: List[Dict[str, Any]]  # ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ì‘ë‹µ
    final_response: str  # í†µí•©ëœ ìµœì¢… ì‘ë‹µ
    agent_success: bool
    agent_type: str  # ì£¼ìš” ì—ì´ì „íŠ¸ íƒ€ì…
    agent_metadata: Dict[str, Any]
    available_agents: List[str]

class LangGraphSupervisor:
    """LangGraph ê¸°ë°˜ Supervisor - ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„í•˜ê³  ì ì ˆí•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self):
        self.llm = self._initialize_llm()
        self.agent_descriptions = agent_registry.get_agent_descriptions()
        self.graph = self._create_agent_graph()
    
    def _initialize_llm(self):
        """LLMì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            print(f" GEMINI_API_KEY í™•ì¸: {settings.GEMINI_API_KEY[:10]}..." if settings.GEMINI_API_KEY else "âŒ GEMINI_API_KEY ì—†ìŒ")
            
            # Gemini API ìš°ì„  ì‚¬ìš©
            if settings.GEMINI_API_KEY:
                print("ğŸš€ Gemini API ì´ˆê¸°í™” ì‹œë„...")
                genai.configure(api_key=settings.GEMINI_API_KEY)
                model = genai.GenerativeModel(settings.GEMINI_MODEL)
                print("âœ… Gemini API ì´ˆê¸°í™” ì„±ê³µ")
                return model
            else:
                print("âŒ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None
        except Exception as e:
            print(f"âŒ LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            return None
    
    def _create_agent_graph(self) -> StateGraph:
        """ì—ì´ì „íŠ¸ ì„ íƒ ë° ì‹¤í–‰ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        workflow = StateGraph(AgentState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("intent_analyzer", self._intent_analyzer_node)
        workflow.add_node("agent_selector", self._agent_selector_node)
        workflow.add_node("agent_executor", self._agent_executor_node)
        
        # ì—£ì§€ ì—°ê²°
        workflow.add_edge(START, "intent_analyzer")
        workflow.add_edge("intent_analyzer", "agent_selector")
        workflow.add_edge("agent_selector", "agent_executor")
        workflow.add_edge("agent_executor", END)
        
        return workflow.compile()
    
    def visualize_graph(self) -> str:
        """LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        try:
            return self.graph.get_graph().draw_mermaid()
        except Exception as e:
            return f"ê·¸ë˜í”„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    def get_graph_info(self) -> Dict[str, Any]:
        """ê·¸ë˜í”„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            graph = self.graph.get_graph()
            return {
                "nodes": list(graph.nodes.keys()),
                "edges": [(edge.source, edge.target) for edge in graph.edges],
                "total_nodes": len(graph.nodes),
                "total_edges": len(graph.edges),
                "framework": "LangGraph"
            }
        except Exception as e:
            return {"error": f"ê·¸ë˜í”„ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}"}
    
    async def _intent_analyzer_node(self, state: AgentState) -> AgentState:
        """ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„í•˜ëŠ” ë…¸ë“œ"""
        try:
            user_input = state["user_input"]
            
            # LLMì„ ì‚¬ìš©í•œ ì˜ë„ ë¶„ì„ (ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ì§€ì›)
            intent_analysis = await self._analyze_intent_with_llm(user_input)
            
            new_state = state.copy()
            new_state["reasoning"] = intent_analysis["reasoning"]
            new_state["selected_agents"] = intent_analysis["selected_agents"]
            new_state["intent_analysis"] = intent_analysis
            
            return new_state
        except Exception as e:
            print(f"ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ì„¤ì •
            new_state = state.copy()
            new_state["reasoning"] = "ì˜ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            new_state["selected_agents"] = ["chatbot"]
            return new_state

    async def _analyze_intent_with_llm(self, user_input: str) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ì§€ì›)."""
        try:
            # LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
            if self.llm is None:
                print("LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì˜ë„ ë¶„ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return self._fallback_intent_analysis(user_input)
            
            # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_llm_intent_prompt(user_input)
            
            if hasattr(self.llm, 'generate_content'):
                # Gemini API ì‚¬ìš©
                response = self.llm.generate_content(prompt)
                analysis_text = response.text
            else:
                # LangChain ëª¨ë¸ ì‚¬ìš©
                from langchain_core.messages import HumanMessage
                messages = [HumanMessage(content=prompt)]
                response = await self.llm.ainvoke(messages)
                analysis_text = response.content
            
            # LLM ì‘ë‹µ íŒŒì‹±
            parsed_analysis = self._parse_llm_response(analysis_text)
            
            return parsed_analysis
            
        except Exception as e:
            print(f"LLM ì˜ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._fallback_intent_analysis(user_input)

    def _fallback_intent_analysis(self, user_input: str) -> Dict[str, Any]:
        """LLMì´ ì—†ì„ ë•Œì˜ ê¸°ë³¸ ì˜ë„ ë¶„ì„"""
        user_input_lower = user_input.lower()
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ì„
        if any(keyword in user_input_lower for keyword in ['ì½”ë“œ', 'í”„ë¡œê·¸ë˜ë°', 'ê°œë°œ', 'í•¨ìˆ˜', 'í´ë˜ìŠ¤', 'ë³€ìˆ˜']):
            return {
                "intent": "coding",
                "confidence": 0.8,
                "reasoning": "ì½”ë”© ê´€ë ¨ í‚¤ì›Œë“œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "selected_agents": ["coding_agent"]
            }
        elif any(keyword in user_input_lower for keyword in ['ëŒ€ì‹œë³´ë“œ', 'ì°¨íŠ¸', 'ê·¸ë˜í”„', 'ë°ì´í„°', 'ë¶„ì„']):
            return {
                "intent": "dashboard",
                "confidence": 0.8,
                "reasoning": "ëŒ€ì‹œë³´ë“œ ê´€ë ¨ í‚¤ì›Œë“œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "selected_agents": ["dashboard_agent"]
            }
        elif any(keyword in user_input_lower for keyword in ['ì¶”ì²œ', 'ì¶”ì²œí•´', 'ì¶”ì²œí•´ì¤˜', 'ì–´ë–¤', 'ë­ê°€ ì¢‹ì„ê¹Œ']):
            return {
                "intent": "recommendation",
                "confidence": 0.8,
                "reasoning": "ì¶”ì²œ ê´€ë ¨ í‚¤ì›Œë“œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "selected_agents": ["recommendation_agent"]
            }
        else:
            return {
                "intent": "chat",
                "confidence": 0.6,
                "reasoning": "ê¸°ë³¸ ì±„íŒ… ì˜ë„ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "selected_agents": ["chatbot"]
            }

    def _create_llm_intent_prompt(self, user_input: str) -> str:
        """LLM ì˜ë„ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        agent_descriptions = "\n".join([
            f"- {agent_type}: {description}"
            for agent_type, description in self.agent_descriptions.items()
        ])
        
        return f"""
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ AI ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ë“¤:
{agent_descriptions}

ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ì—ì´ì „íŠ¸ê°€ ê°€ì¥ ì í•©í•œì§€ íŒë‹¨í•˜ê³ , ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ë³µì¡í•œ ìš”ì²­ì˜ ê²½ìš° ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ì¡°í•©í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "selected_agents": ["ì—ì´ì „íŠ¸1", "ì—ì´ì „íŠ¸2"],
    "primary_agent": "ì£¼ìš” ì—ì´ì „íŠ¸ëª…",
    "confidence": 0.95,
    "reasoning": "ì„ íƒ ì´ìœ ì™€ ì—ì´ì „íŠ¸ ì¡°í•© ì´ìœ  ì„¤ëª…",
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
    "intent": "ì‚¬ìš©ì ì˜ë„ ìš”ì•½",
    "agent_workflow": "ì—ì´ì „íŠ¸ ì‹¤í–‰ ìˆœì„œì™€ ì—­í•  ì„¤ëª…"
}}

ì—ì´ì „íŠ¸ ì„ íƒ ê¸°ì¤€:
- coding: ì½”ë“œ ì‘ì„±, ë””ë²„ê¹…, í”„ë¡œê·¸ë˜ë° ê´€ë ¨ ì§ˆë¬¸
- dashboard: ë°ì´í„° ì‹œê°í™”, ì°¨íŠ¸, ë¶„ì„, í†µê³„ ê´€ë ¨ ì§ˆë¬¸
- recommendation: ì¶”ì²œ, ì œì•ˆ, ì¶”ì²œí•´ì¤˜ ë“±ì˜ ìš”ì²­
- chatbot: ì¼ë°˜ì ì¸ ì§ˆë¬¸, ì´ë¯¸ì§€ ë¶„ì„, ë©€í‹°ëª¨ë‹¬ ì§ˆë¬¸

ë³µí•© ìš”ì²­ ì˜ˆì‹œ:
- "ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ëŒ€ì‹œë³´ë“œë¡œ ì‹œê°í™”í•´ì¤˜" â†’ ["coding", "dashboard"]
- "ì¶”ì²œí•´ì£¼ê³  ë¶„ì„ ê²°ê³¼ë¥¼ ì°¨íŠ¸ë¡œ ë³´ì—¬ì¤˜" â†’ ["recommendation", "dashboard"]
- "ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì½”ë“œë¡œ êµ¬í˜„í•´ì¤˜" â†’ ["chatbot", "coding"]

ì‚¬ìš©ì ë©”ì‹œì§€: {user_input}

JSON ì‘ë‹µë§Œ ì œê³µí•´ì£¼ì„¸ìš”:
"""

    def _parse_llm_response(self, response_text: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
        try:
            import json
            import re
            
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                parsed = json.loads(json_str)
                
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •
                if "selected_agents" not in parsed:
                    parsed["selected_agents"] = ["chatbot"]
                if "primary_agent" not in parsed:
                    parsed["primary_agent"] = parsed["selected_agents"][0] if parsed["selected_agents"] else "chatbot"
                if "reasoning" not in parsed:
                    parsed["reasoning"] = "LLM ë¶„ì„ ê²°ê³¼"
                if "confidence" not in parsed:
                    parsed["confidence"] = 0.8
                if "keywords" not in parsed:
                    parsed["keywords"] = []
                if "intent" not in parsed:
                    parsed["intent"] = "ì‚¬ìš©ì ì˜ë„ ë¶„ì„"
                if "agent_workflow" not in parsed:
                    parsed["agent_workflow"] = "ì—ì´ì „íŠ¸ ì‹¤í–‰ ìˆœì„œ: " + " â†’ ".join(parsed["selected_agents"])
                
                return parsed
            else:
                # JSONì´ ì—†ìœ¼ë©´ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°±
                return 
                
        except Exception as e:
            print(f"LLM ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {}

    async def _agent_selector_node(self, state: AgentState) -> AgentState:
        """ì ì ˆí•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” ë…¸ë“œ"""
        try:
            user_input = state["user_input"]
            reasoning = state["reasoning"]
            selected_agents = state.get("selected_agents", ["chatbot"])
            
            new_state = state.copy()
            new_state["selected_agents"] = selected_agents
            new_state["available_agents"] = list(self.agent_descriptions.keys())
            return new_state
            
        except Exception as e:
            new_state = state.copy()
            new_state["selected_agents"] = ["chatbot"]  # ê¸°ë³¸ê°’
            new_state["reasoning"] += f" ì—ì´ì „íŠ¸ ì„ íƒ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            return new_state
    
    async def _agent_executor_node(self, state: AgentState) -> AgentState:
        """ì„ íƒëœ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ë…¸ë“œ"""
        try:
            selected_agents = state["selected_agents"]
            user_input = state["user_input"]
            user_id = state["user_id"]
            
            agent_responses = []
            final_response = ""
            agent_success = True
            primary_agent_type = "unknown"
            
            # ê° ì—ì´ì „íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰
            for i, agent_type in enumerate(selected_agents):
                try:
                    # ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                    agent = agent_registry.get_agent(agent_type)
                    
                    if agent:
                        # ìƒˆë¡œìš´ process(state) íŒ¨í„´ì— ë§ëŠ” ìƒíƒœ ìƒì„±
                        agent_state = {
                            "question": user_input,
                            "user_id": user_id,
                            "session_id": state.get("user_context", {}).get("session_id"),
                            "filters": state.get("user_context", {}).get("filters", {}),
                            "time_hint": state.get("user_context", {}).get("time_hint"),
                            "context": state.get("user_context", {})
                        }
                        
                        # ìƒˆë¡œìš´ process(state) íŒ¨í„´ìœ¼ë¡œ ì—ì´ì „íŠ¸ ì‹¤í–‰
                        if hasattr(agent, 'process') and callable(getattr(agent, 'process')):
                            # ìƒˆë¡œìš´ íŒ¨í„´ ì‚¬ìš©
                            result_state = agent.process(agent_state)
                            
                            # ì‘ë‹µ ìˆ˜ì§‘
                            agent_response = {
                                "agent_type": agent_type,
                                "content": result_state.get("answer", ""),
                                "success": True,  # process()ëŠ” ì„±ê³µ ì‹œì—ë§Œ í˜¸ì¶œë¨
                                "metadata": result_state.get("metadata", {}),
                                "evidence": result_state.get("evidence", []),
                                "order": i + 1
                            }
                        else:
                            # ê¸°ì¡´ async íŒ¨í„´ ì‚¬ìš© (í˜¸í™˜ì„±)
                            result = await agent.process_async(user_input, user_id)
                            agent_response = {
                                "agent_type": agent_type,
                                "content": result.content,
                                "success": result.success,
                                "metadata": result.metadata,
                                "evidence": [],
                                "order": i + 1
                            }
                        
                        agent_responses.append(agent_response)
                        
                        # ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¥¼ ì£¼ìš” ì—ì´ì „íŠ¸ë¡œ ì„¤ì •
                        if i == 0:
                            primary_agent_type = agent_type
                            final_response = agent_response["content"]
                        
                        # ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì „ì²´ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
                        if not agent_response["success"]:
                            agent_success = False
                            
                    else:
                        # ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
                        agent_responses.append({
                            "agent_type": agent_type,
                            "content": f"ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {agent_type}",
                            "success": False,
                            "metadata": {},
                            "evidence": [],
                            "order": i + 1
                        })
                        agent_success = False
                        
                except Exception as e:
                    # ê°œë³„ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜
                    agent_responses.append({
                        "agent_type": agent_type,
                        "content": f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                        "success": False,
                        "metadata": {"error": str(e)},
                        "evidence": [],
                        "order": i + 1
                    })
                    agent_success = False
            
            # ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ì‘ë‹µì„ í†µí•©
            if len(agent_responses) > 1:
                final_response = self._combine_agent_responses(agent_responses, user_input)
            
            new_state = state.copy()
            new_state["agent_responses"] = agent_responses
            new_state["final_response"] = final_response
            new_state["agent_success"] = agent_success
            new_state["agent_type"] = primary_agent_type
            new_state["agent_metadata"] = {
                "total_agents": len(selected_agents),
                "executed_agents": [resp["agent_type"] for resp in agent_responses],
                "successful_agents": [resp["agent_type"] for resp in agent_responses if resp["success"]],
                "failed_agents": [resp["agent_type"] for resp in agent_responses if not resp["success"]]
            }
            
            return new_state
                
        except Exception as e:
            new_state = state.copy()
            new_state["agent_responses"] = []
            new_state["final_response"] = f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            new_state["agent_success"] = False
            new_state["agent_type"] = "unknown"
            new_state["agent_metadata"] = {"error": str(e)}
            return new_state
    
    def _create_intent_analysis_prompt(self, user_message: str) -> str:
        """ì˜ë„ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        agent_descriptions = "\n".join([
            f"- {agent_type}: {description}"
            for agent_type, description in self.agent_descriptions.items()
        ])
        
        return f"""
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ AI ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ë“¤:
{agent_descriptions}

ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ì—ì´ì „íŠ¸ê°€ ê°€ì¥ ì í•©í•œì§€ íŒë‹¨í•˜ê³ , ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
- ì£¼ìš” í‚¤ì›Œë“œ: [ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” í‚¤ì›Œë“œë“¤]
- ì˜ë„ ë¶„ì„: [ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê²ƒì´ ë¬´ì—‡ì¸ì§€ ë¶„ì„]
- ì¶”ì²œ ì—ì´ì „íŠ¸: [ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ëª…]
- ì„ íƒ ì´ìœ : [ì™œ í•´ë‹¹ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí–ˆëŠ”ì§€ ì„¤ëª…]

ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}
"""
    
    async def process_user_intent(self, user_intent: UserIntent) -> SupervisorResponse:
        """ì‚¬ìš©ì ì˜ë„ë¥¼ ì²˜ë¦¬í•˜ê³  ì ì ˆí•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤ (LangGraph ê¸°ë°˜)."""
        try:
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = {
                "messages": [],
                "user_input": user_intent.message,
                "user_id": user_intent.user_id,
                "user_context": user_intent.context,
                "selected_agents": [],
                "reasoning": "",
                "agent_responses": [],
                "final_response": "",
                "agent_success": False,
                "agent_type": "",
                "agent_metadata": {},
                "available_agents": []
            }
            
            # ê·¸ë˜í”„ ì‹¤í–‰
            result = await self.graph.ainvoke(initial_state)
            
            # ê²°ê³¼ë¥¼ SupervisorResponseë¡œ ë³€í™˜
            return SupervisorResponse(
                success=result["agent_success"],
                selected_agent=result.get("selected_agents", [result["agent_type"]])[0],  # ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸
                response=AgentResponse(
                    success=result["agent_success"],
                    content=result["final_response"],
                    agent_type=result["agent_type"],
                    metadata=result["agent_metadata"]
                ),
                reasoning=result["reasoning"],
                metadata={
                    "available_agents": result["available_agents"],
                    "user_context": user_intent.context,
                    "graph_execution": True,
                    "selected_agents": result.get("selected_agents", []),
                    "agent_responses": result.get("agent_responses", [])
                }
            )
            
        except Exception as e:
            return SupervisorResponse(
                success=False,
                selected_agent="unknown",
                response=AgentResponse(
                    success=False,
                    content=f"LangGraph ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                    agent_type="unknown"
                ),
                reasoning="ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                metadata={"error": str(e), "graph_execution": True}
            )
    
    def get_available_agents(self) -> Dict[str, str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.agent_descriptions
    
    def add_agent(self, agent_type: str, agent: BaseAgent):
        """ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        agent_registry.register_agent(agent)
        self.agent_descriptions = agent_registry.get_agent_descriptions()
    
    def remove_agent(self, agent_type: str):
        """ì—ì´ì „íŠ¸ë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
        agent_registry.unregister_agent(agent_type)
        self.agent_descriptions = agent_registry.get_agent_descriptions()

    def _combine_agent_responses(self, agent_responses: List[Dict[str, Any]], user_input: str) -> str:
        """ì—¬ëŸ¬ ì—ì´ì „íŠ¸ì˜ ì‘ë‹µì„ ì§€ëŠ¥ì ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤."""
        try:
            if not agent_responses:
                return "ì—ì´ì „íŠ¸ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."
            
            if len(agent_responses) == 1:
                return agent_responses[0]["content"]
            
            # ì„±ê³µí•œ ì—ì´ì „íŠ¸ ì‘ë‹µë§Œ í•„í„°ë§
            successful_responses = [resp for resp in agent_responses if resp["success"]]
            
            if not successful_responses:
                return "ëª¨ë“  ì—ì´ì „íŠ¸ ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            # ì—ì´ì „íŠ¸ íƒ€ì…ë³„ë¡œ ì‘ë‹µ ë¶„ë¥˜
            response_by_type = {}
            for resp in successful_responses:
                agent_type = resp["agent_type"]
                if agent_type not in response_by_type:
                    response_by_type[agent_type] = []
                response_by_type[agent_type].append(resp["content"])
            
            # í†µí•©ëœ ì‘ë‹µ ìƒì„±
            combined_response = "ì—¬ëŸ¬ ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¥¼ í†µí•©í–ˆìŠµë‹ˆë‹¤:\n\n"
            
            for agent_type, responses in response_by_type.items():
                combined_response += f"**{agent_type.upper()} ì—ì´ì „íŠ¸ ê²°ê³¼:**\n"
                for i, response in enumerate(responses, 1):
                    combined_response += f"{i}. {response}\n"
                combined_response += "\n"
            
            # ìš”ì•½ ì¶”ê°€
            combined_response += f"ì´ {len(successful_responses)}ê°œì˜ ì—ì´ì „íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
            
            return combined_response
            
        except Exception as e:
            print(f"ì—ì´ì „íŠ¸ ì‘ë‹µ í†µí•© ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì²« ë²ˆì§¸ ì„±ê³µí•œ ì‘ë‹µ ë°˜í™˜
            for resp in agent_responses:
                if resp["success"]:
                    return resp["content"]
            return "ì—ì´ì „íŠ¸ ì‘ë‹µ í†µí•© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ì „ì—­ Supervisor ì¸ìŠ¤í„´ìŠ¤ (LangGraph ê¸°ë°˜)
supervisor = LangGraphSupervisor() 